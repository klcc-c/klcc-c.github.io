<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"klcc.cc","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="Scrapy的使用">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy爬虫框架">
<meta property="og:url" content="https://klcc.cc/8386228b.html">
<meta property="og:site_name" content="klcc">
<meta property="og:description" content="Scrapy的使用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://klcc-img-1251900471.cos.ap-chengdu.myqcloud.com/img/e6c9d24egy1h09n48vwmpj212w0q4go1.jpg">
<meta property="article:published_time" content="2022-02-08T03:18:08.406Z">
<meta property="article:modified_time" content="2022-05-11T12:09:50.830Z">
<meta property="article:author" content="klcc">
<meta property="article:tag" content="crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://klcc-img-1251900471.cos.ap-chengdu.myqcloud.com/img/e6c9d24egy1h09n48vwmpj212w0q4go1.jpg">


<link rel="canonical" href="https://klcc.cc/8386228b.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://klcc.cc/8386228b.html","path":"8386228b.html","title":"Scrapy爬虫框架"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Scrapy爬虫框架 | klcc</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?725ad6b586949dd6e89c022fb8d748f7"></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">klcc</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">33</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">27</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">157</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.</span> <span class="nav-text">Scrapy的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-number">2.</span> <span class="nav-text">Scrapy目录结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">Scrapy架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E8%BF%90%E8%A1%8C%E7%88%AC%E8%99%AB"><span class="nav-number">4.</span> <span class="nav-text">配置运行爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE"><span class="nav-number">5.</span> <span class="nav-text">Scrapy解析数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-spiders-cnblogs-py"><span class="nav-number">5.1.</span> <span class="nav-text">first_scrapy&#x2F;spiders&#x2F;cnblogs.py</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#css"><span class="nav-number">5.1.1.</span> <span class="nav-text">css</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#xpath"><span class="nav-number">5.1.2.</span> <span class="nav-text">xpath</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#setting%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E"><span class="nav-number">6.</span> <span class="nav-text">setting配置说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E7%AB%99%E7%88%AC%E5%8F%96cnblogs%E6%96%87%E7%AB%A0"><span class="nav-number">7.</span> <span class="nav-text">全站爬取cnblogs文章</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-spiders-cnblogs-py-1"><span class="nav-number">7.1.</span> <span class="nav-text">first_scrapy&#x2F;spiders&#x2F;cnblogs.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-items-py"><span class="nav-number">7.2.</span> <span class="nav-text">first_scrapy&#x2F;items.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-settings-py"><span class="nav-number">7.3.</span> <span class="nav-text">first_scrapy&#x2F;settings.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-pipelines-py"><span class="nav-number">7.4.</span> <span class="nav-text">first_scrapy&#x2F;pipelines.py</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="nav-number">8.</span> <span class="nav-text">下载中间件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-settings-py-1"><span class="nav-number">8.1.</span> <span class="nav-text">first_scrapy&#x2F;settings.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#first-scrapy-middlewares-py"><span class="nav-number">8.2.</span> <span class="nav-text">first_scrapy&#x2F;middlewares.py</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="klcc"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">klcc</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://klcc.cc/8386228b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="klcc">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="klcc">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Scrapy爬虫框架
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
  
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-08 11:18:08" itemprop="dateCreated datePublished" datetime="2022-02-08T11:18:08+08:00">2022-02-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/crawler/" itemprop="url" rel="index"><span itemprop="name">crawler</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>10k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="Scrapy的使用"><a href="#Scrapy的使用" class="headerlink" title="Scrapy的使用"></a><code>Scrapy</code>的使用</h3><span id="more"></span>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">scrapy: 是一个框架，类似于djagno框架，在固定的位置写固定的代码即可</span><br><span class="line">基于这个框架写一个爬虫项目</span><br><span class="line"></span><br><span class="line">安装</span><br><span class="line">  pip3 install scrapy</span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   win上可能装不上（90%都能装上）其实是因为twisted装不上</span></span><br><span class="line"><span class="string">	 pip3 install wheel  装了它，以后支持直接使用whl文件安装</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">   安装后，便支持通过wheel文件安装软件，wheel文件官网：https://www.lfd.uci.edu/~gohlke/pythonlibs</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">   pip3 install lxml</span></span><br><span class="line"><span class="string">   pip3 install pyopenssl</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">   下载并安装pywin32：https://sourceforge.net/projects/pywin32/files/pywin32/</span></span><br><span class="line"><span class="string">   下载twisted的wheel文件：http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted</span></span><br><span class="line"><span class="string">   执行pip3 install 下载目录\Twisted-17.9.0-cp36-cp36m-win_amd64.whl</span></span><br><span class="line"><span class="string">   pip3 install scrapy</span></span><br><span class="line"><span class="string">  &#x27;&#x27;&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 命令行创建项目</span></span><br><span class="line">  scrapy startproject myfirst</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建爬虫  scrapy genspider  爬虫名  爬虫地址</span></span><br><span class="line">  scrapy genspider cnblogs www.cnblogs.com</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 运行爬虫</span></span><br><span class="line">  scrapy crawl cnblogs</span><br></pre></td></tr></table></figure>

<h3 id="Scrapy目录结构"><a href="#Scrapy目录结构" class="headerlink" title="Scrapy目录结构"></a><code>Scrapy</code>目录结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">├── first_scrapy         <span class="comment"># 项目名字</span></span><br><span class="line">│   ├── items.py         <span class="comment"># 模型类写了一些字段，类似于django的models</span></span><br><span class="line">│   ├── middlewares.py   <span class="comment"># 中间件：爬虫中间件和下载中间件 </span></span><br><span class="line">│   ├── pipelines.py     <span class="comment"># 管道：存储数据的代码写在这</span></span><br><span class="line">│   ├── settings.py      <span class="comment"># 项目的配置文件</span></span><br><span class="line">│   └── spiders          <span class="comment"># 文件夹，下面放了一个个爬虫文件</span></span><br><span class="line">│       └── cnblogs.py   <span class="comment"># 一个个的爬虫文件</span></span><br><span class="line">└── scrapy.cfg           <span class="comment"># 项目上线需要用到，不用管</span></span><br></pre></td></tr></table></figure>

<h3 id="Scrapy架构"><a href="#Scrapy架构" class="headerlink" title="Scrapy架构"></a><code>Scrapy</code>架构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引擎(EGINE)--&gt;大总管，负责全部的数据流向--》内置的，咱们不需要写</span></span><br><span class="line"></span><br><span class="line">引擎负责控制系统所有组件之间的数据流，并在某些动作发生时触发事件</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调度器(SCHEDULER)---》对要爬取的地址进行排队，去重</span></span><br><span class="line">用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL的优先级队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载器(DOWLOADER)--》真正负责下载---》高效的异步模型</span></span><br><span class="line">用于下载网页内容, 并将网页内容返回给EGINE，下载器是建立在twisted这个高效的异步模型上的</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬虫(SPIDERS)--》咱们重点写的地方，解析响应，从响应中提取要保存的数据和下一次爬取的地址</span></span><br><span class="line">SPIDERS是开发人员自定义的类，用来解析responses，并且提取items，或者发送新的请求</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目管道(ITEM PIPLINES)---》存储数据的逻辑---》可以存到文件，redis，mysql。。。</span></span><br><span class="line">在items被提取后负责处理它们，主要包括清理、验证、持久化（比如存到数据库）等操作</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载器中间件(Downloader Middlewares)--》用的多</span></span><br><span class="line">位于Scrapy引擎和下载器之间，主要用来处理从EGINE传到DOWLOADER的请求request(加请求头，加cookie，加代理)，已经从DOWNLOADER传到EGINE的响应response进行一些处理</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬虫中间件(Spider Middlewares)---》用的少</span></span><br><span class="line">位于EGINE和SPIDERS之间，主要工作是处理SPIDERS的输入（即responses）和输出（即requests）</span><br></pre></td></tr></table></figure>

<p><img src="https://klcc-img-1251900471.cos.ap-chengdu.myqcloud.com/img/e6c9d24egy1h09n48vwmpj212w0q4go1.jpg" alt="img"></p>
<h3 id="配置运行爬虫"><a href="#配置运行爬虫" class="headerlink" title="配置运行爬虫"></a>配置运行爬虫</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># first_scrapy/run.py  pycharm中的运行</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmdline.execute([&#x27;scrapy&#x27;, &#x27;crawl&#x27; ,&#x27;cnblogs&#x27;,&#x27;--nolog&#x27;])</span></span><br><span class="line">cmdline.execute([<span class="string">&#x27;scrapy&#x27;</span>, <span class="string">&#x27;crawl&#x27;</span>, <span class="string">&#x27;cnblogs&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="Scrapy解析数据"><a href="#Scrapy解析数据" class="headerlink" title="Scrapy解析数据"></a><code>Scrapy</code>解析数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> response对象有css方法和xpath方法</span><br><span class="line">    css中写css选择器</span><br><span class="line">    xpath中写xpath选择</span><br><span class="line">    </span><br><span class="line"><span class="number">2.</span> </span><br><span class="line">	 xpath取文本内容</span><br><span class="line">		<span class="string">&#x27;.//a[contains(@class,&quot;link-title&quot;)]/text()&#x27;</span></span><br><span class="line">   xpath取属性</span><br><span class="line">    <span class="string">&#x27;.//a[contains(@class,&quot;link-title&quot;)]/@href&#x27;</span></span><br><span class="line">   css取文本</span><br><span class="line">    <span class="string">&#x27;a.link-title::text&#x27;</span></span><br><span class="line">   css取属性</span><br><span class="line">    <span class="string">&#x27;img.image-scale::attr(src)&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="number">3.</span></span><br><span class="line">	 .extract_first()   取一个</span><br><span class="line">   .extract()         取所有</span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-spiders-cnblogs-py"><a href="#first-scrapy-spiders-cnblogs-py" class="headerlink" title="first_scrapy/spiders/cnblogs.py"></a><code>first_scrapy/spiders/cnblogs.py</code></h4><h5 id="css"><a href="#css" class="headerlink" title="css"></a><code>css</code></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpider</span>(<span class="params">scrapy.Spider</span>):</span>  <span class="comment"># 爬虫类</span></span><br><span class="line">    name = <span class="string">&#x27;cnblogs&#x27;</span>  <span class="comment"># 爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.cnblogs.com&#x27;</span>]  <span class="comment"># 允许爬取的域 只爬取该域下的</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.cnblogs.com/&#x27;</span>]  <span class="comment"># 起始爬取的地址</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span>  <span class="comment"># 解析方法 爬取完后的 response 会到这执行</span></span><br><span class="line">        <span class="comment"># print(response)  # 从 response 解析数据</span></span><br><span class="line">        <span class="comment"># 解析出文章的标题 摘要 作者 作者头像 并继续爬取出文章详情</span></span><br><span class="line">        <span class="comment"># 将爬取的结果组装成一个对象存起来</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用 bs4 解析出需要的数据 scrapy 自带解析库 不需要bs4 支持 css 和 xpath</span></span><br><span class="line">        <span class="comment"># print(response.text)</span></span><br><span class="line"></span><br><span class="line">        article_list = response.css(<span class="string">&#x27;article.post-item&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> article_list:</span><br><span class="line">            <span class="comment"># 获取标题</span></span><br><span class="line">            title = article.css(<span class="string">&#x27;section &gt; div &gt; a::text&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment"># title = article.css(&#x27;section &gt; div &gt; a::text&#x27;).extract()[0]  # 和上面相等</span></span><br><span class="line">            <span class="comment"># print(title)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取摘要</span></span><br><span class="line">            desc = article.css(<span class="string">&#x27;section &gt; div &gt; p::text&#x27;</span>).extract()[<span class="number">0</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> desc:</span><br><span class="line">                desc = article.css(<span class="string">&#x27;section &gt; div &gt; p::text&#x27;</span>).extract()[<span class="number">1</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="comment"># print(desc)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 作者名称</span></span><br><span class="line">            author_name = article.css(<span class="string">&#x27;section &gt; footer &gt; a &gt; span::text&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment"># print(author_name)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 作者头像</span></span><br><span class="line">            author_img = article.css(<span class="string">&#x27;section &gt; div &gt; p &gt; a &gt; img::attr(src)&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment"># print(author_img)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 文章详情地址</span></span><br><span class="line">            article_url = article.css(<span class="string">&#x27;section &gt; div &gt; a::attr(href)&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment"># print(article_url)</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                文章标题:<span class="subst">&#123;title&#125;</span>,</span></span><br><span class="line"><span class="string">                文章摘要:<span class="subst">&#123;desc&#125;</span>,</span></span><br><span class="line"><span class="string">                作者名称:<span class="subst">&#123;author_name&#125;</span>,</span></span><br><span class="line"><span class="string">                作者头像:<span class="subst">&#123;author_img&#125;</span>,</span></span><br><span class="line"><span class="string">                文章详情:<span class="subst">&#123;article_url&#125;</span>,</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="xpath"><a href="#xpath" class="headerlink" title="xpath"></a><code>xpath</code></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpider</span>(<span class="params">scrapy.Spider</span>):</span>  </span><br><span class="line">    name = <span class="string">&#x27;cnblogs&#x27;</span> </span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.cnblogs.com&#x27;</span>]  </span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.cnblogs.com/&#x27;</span>]  </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span>  </span><br><span class="line">        article_list = response.xpath(<span class="string">&#x27;//article[@class=&quot;post-item&quot;]&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> article_list:</span><br><span class="line">            <span class="comment"># 获取标题</span></span><br><span class="line">            title = article.xpath(<span class="string">&#x27;./section/div/a/text()&#x27;</span>).extract_first()</span><br><span class="line">            desc = article.xpath(<span class="string">&#x27;./section/div/p/text()&#x27;</span>).extract()[<span class="number">0</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> desc:</span><br><span class="line">                desc = article.xpath(<span class="string">&#x27;./section/div/p/text()&#x27;</span>).extract()[<span class="number">1</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="comment"># 作者名称</span></span><br><span class="line">            author_name = article.xpath(<span class="string">&#x27;./section/footer/a/span/text()&#x27;</span>).extract_first()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 作者头像</span></span><br><span class="line">            author_img = article.xpath(<span class="string">&#x27;./section/div/p/a/img/@src&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 文章详情地址</span></span><br><span class="line">            article_url = article.xpath(<span class="string">&#x27;./section/div/a/@href&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                文章标题:<span class="subst">&#123;title&#125;</span>,</span></span><br><span class="line"><span class="string">                文章摘要:<span class="subst">&#123;desc&#125;</span>,</span></span><br><span class="line"><span class="string">                作者名称:<span class="subst">&#123;author_name&#125;</span>,</span></span><br><span class="line"><span class="string">                作者头像:<span class="subst">&#123;author_img&#125;</span>,</span></span><br><span class="line"><span class="string">                文章详情:<span class="subst">&#123;article_url&#125;</span>,</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="setting配置说明"><a href="#setting配置说明" class="headerlink" title="setting配置说明"></a><code>setting</code>配置说明</h3><p><code>first_scrapy/settings.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 内置一套，用户一套</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span>     <span class="comment"># 是否遵循爬虫协议，如果写了它，一般网站都不让爬，基本写成false</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;浏览器头&#x27;</span>     <span class="comment"># 爬虫请求头中USER_AGENT是什么，做成浏览器的样子</span></span><br><span class="line">LOG_LEVEL=<span class="string">&#x27;ERROR&#x27;</span>          <span class="comment"># 日志级别改成ERROR，以后错误日志会打印，普通日志不打印</span></span><br><span class="line">SPIDER_MIDDLEWARES=[]      <span class="comment"># 爬虫中间件，可以写多个</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES=[]  <span class="comment"># 下载中间件类，配置在这，可以配多个</span></span><br><span class="line">ITEM_PIPELINES=[]          <span class="comment"># 保存数据，会执行到的类，类内部写保存逻辑</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 增加并发</span></span><br><span class="line">默认scrapy开启的并发线程为<span class="number">32</span>个，可以适当进行增加。在settings配置文件中修改CONCURRENT_REQUESTS = <span class="number">100</span>值为<span class="number">100</span>,并发设置成了为<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 降低日志级别</span></span><br><span class="line">在运行scrapy时，会有大量日志信息的输出，为了减少CPU的使用率。可以设置log输出信息为INFO或者ERROR即可。在配置文件中编写：LOG_LEVEL = <span class="string">&#x27;INFO&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 禁止cookie</span></span><br><span class="line">如果不是真的需要cookie，则在scrapy爬取数据时可以禁止cookie从而减少CPU的使用率，提升爬取效率。在配置文件中编写：COOKIES_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 4 禁止重试</span></span><br><span class="line">对失败的HTTP进行重新请求（重试）会减慢爬取速度，因此可以禁止重试。在配置文件中编写：RETRY_ENABLED = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5 减少下载超时</span></span><br><span class="line">如果对一个非常慢的链接进行爬取，减少下载超时可以能让卡住的链接快速被放弃，从而提升效率。在配置文件中进行编写：DOWNLOAD_TIMEOUT = <span class="number">10</span> 超时时间为10s</span><br></pre></td></tr></table></figure>

<h3 id="全站爬取cnblogs文章"><a href="#全站爬取cnblogs文章" class="headerlink" title="全站爬取cnblogs文章"></a>全站爬取cnblogs文章</h3><h4 id="first-scrapy-spiders-cnblogs-py-1"><a href="#first-scrapy-spiders-cnblogs-py-1" class="headerlink" title="first_scrapy/spiders/cnblogs.py"></a><code>first_scrapy/spiders/cnblogs.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> FirstScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpider</span>(<span class="params">scrapy.Spider</span>):</span>  <span class="comment"># 爬虫类</span></span><br><span class="line">    name = <span class="string">&#x27;cnblogs&#x27;</span>  <span class="comment"># 爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.cnblogs.com&#x27;</span>]  <span class="comment"># 允许爬取的域 只爬取该域下的</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.cnblogs.com/&#x27;</span>]  <span class="comment"># 起始爬取的地址</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span>  <span class="comment"># 解析方法 爬取完后的 response 会到这执行</span></span><br><span class="line">        article_list = response.css(<span class="string">&#x27;article.post-item&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> article_list:</span><br><span class="line">            title = article.css(<span class="string">&#x27;section &gt; div &gt; a::text&#x27;</span>).extract_first()</span><br><span class="line">            desc = article.css(<span class="string">&#x27;section &gt; div &gt; p::text&#x27;</span>).extract()[<span class="number">0</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> desc:</span><br><span class="line">                desc = article.css(<span class="string">&#x27;section &gt; div &gt; p::text&#x27;</span>).extract()[<span class="number">1</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            author_name = article.css(<span class="string">&#x27;section &gt; footer &gt; a &gt; span::text&#x27;</span>).extract_first()</span><br><span class="line">            author_img = article.css(<span class="string">&#x27;section &gt; div &gt; p &gt; a &gt; img::attr(src)&#x27;</span>).extract_first()</span><br><span class="line">            article_url = article.css(<span class="string">&#x27;section &gt; div &gt; a::attr(href)&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 需要一个文章对象 属于items中模型类的对象</span></span><br><span class="line">            item = FirstScrapyItem()</span><br><span class="line">            <span class="comment"># 必须使用 [] 不能使用 .  赋值</span></span><br><span class="line">            item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">            item[<span class="string">&#x27;desc&#x27;</span>] = desc</span><br><span class="line">            item[<span class="string">&#x27;author_name&#x27;</span>] = author_name</span><br><span class="line">            item[<span class="string">&#x27;author_img&#x27;</span>] = author_img</span><br><span class="line">            <span class="comment"># 缺文章详情 detail</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 继续爬取文章详情页 文章详情页的解析方法不能继续使用这个 需要一个单独的解析方法 爬完会触发</span></span><br><span class="line">            <span class="keyword">yield</span> Request(url=article_url, callback=self.parse_detail, meta=&#123;<span class="string">&quot;item&quot;</span>: item&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下一页地址</span></span><br><span class="line">        next_url = <span class="string">&#x27;https://www.cnblogs.com&#x27;</span> + response.css(</span><br><span class="line">            <span class="string">&#x27;#paging_block &gt; div &gt; a:last-child::attr(href)&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># next_url = &#x27;https://www.cnblogs.com&#x27; + response.xpath(</span></span><br><span class="line">        <span class="comment">#     &#x27;//*[@id=&quot;paging_block&quot;]/div/a[last()]/@href&#x27;).extract_first()</span></span><br><span class="line">        <span class="comment"># print(next_url)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 继续爬取下一页 再爬完 解析方式 还是这个解析方式</span></span><br><span class="line">        <span class="keyword">yield</span> Request(url=next_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># 解析出文章详情 需要对上之前文章的数据</span></span><br><span class="line">        item = response.meta.get(<span class="string">&#x27;item&#x27;</span>)</span><br><span class="line">        detail = <span class="built_in">str</span>(response.css(<span class="string">&#x27;#cnblogs_post_body&#x27;</span>).extract_first())</span><br><span class="line">        item[<span class="string">&#x27;detail&#x27;</span>] = detail</span><br><span class="line">        <span class="keyword">yield</span> item  <span class="comment"># 触发 pipeline 走存储</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-items-py"><a href="#first-scrapy-items-py" class="headerlink" title="first_scrapy/items.py"></a><code>first_scrapy/items.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FirstScrapyItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    desc = scrapy.Field()</span><br><span class="line">    author_name = scrapy.Field()</span><br><span class="line">    author_img = scrapy.Field()</span><br><span class="line">    detail = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-settings-py"><a href="#first-scrapy-settings-py" class="headerlink" title="first_scrapy/settings.py"></a><code>first_scrapy/settings.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;first_scrapy.pipelines.FirstScrapyPipeline&#x27;</span>: <span class="number">300</span>,  <span class="comment"># 此处可以配多个 数字越小 优先级越高</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-pipelines-py"><a href="#first-scrapy-pipelines-py" class="headerlink" title="first_scrapy/pipelines.py"></a><code>first_scrapy/pipelines.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FirstScrapyPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;先打开&quot;</span>)</span><br><span class="line">        self.conn = pymysql.connect(</span><br><span class="line">            user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">            password=<span class="string">&quot;asd123...&quot;</span>,</span><br><span class="line">            host=<span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">            database=<span class="string">&#x27;cnblogs&#x27;</span>,</span><br><span class="line">            port=<span class="number">3306</span>,</span><br><span class="line">            autocommit=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        self.curosr = self.conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment"># 会一次次触发该方法的执行  在这里写保存的逻辑</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;pipeline: &#x27;</span>,item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">				<span class="comment"># 存入MySQl数据库中</span></span><br><span class="line">        self.curosr.execute(<span class="string">&#x27;insert into article &#x27;</span></span><br><span class="line">                            <span class="string">&#x27;(title,`desc`,author_name,author_img,detail) values &#x27;</span></span><br><span class="line">                            <span class="string">&#x27;(%s,%s,%s,%s,%s)&#x27;</span>,</span><br><span class="line">                            args=[item[<span class="string">&#x27;title&#x27;</span>], item[<span class="string">&#x27;desc&#x27;</span>], item[<span class="string">&#x27;author_name&#x27;</span>], item[<span class="string">&#x27;author_img&#x27;</span>], item[<span class="string">&#x27;detail&#x27;</span>]])</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我关闭了&quot;</span>)</span><br><span class="line">        self.curosr.close()</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure>

<h3 id="下载中间件"><a href="#下载中间件" class="headerlink" title="下载中间件"></a>下载中间件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬虫和下载中间件要使用 需要在配置文件中配置</span></span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">  <span class="string">&#x27;crawl_cnblogs.middlewares.CrawlCnblogsSpiderMiddleware&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载中间件</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">  <span class="string">&#x27;crawl_cnblogs.middlewares.CrawlCnblogsDownloaderMiddleware&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-settings-py-1"><a href="#first-scrapy-settings-py-1" class="headerlink" title="first_scrapy/settings.py"></a><code>first_scrapy/settings.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;first_scrapy.middlewares.FirstScrapyDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h4 id="first-scrapy-middlewares-py"><a href="#first-scrapy-middlewares-py" class="headerlink" title="first_scrapy/middlewares.py"></a><code>first_scrapy/middlewares.py</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FirstScrapyDownloaderMiddleware</span>:</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 请求来</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="comment"># 修改为随机 User-Agent</span></span><br><span class="line">        <span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        request.headers[<span class="string">&quot;User-Agent&quot;</span>] = ua.random</span><br><span class="line">        <span class="built_in">print</span>(request.headers[<span class="string">b&#x27;User-Agent&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加入cookie</span></span><br><span class="line">        <span class="comment"># request.cookies = &#123;&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加代理 可以写一个方法 将代理池的代理取出放到这里</span></span><br><span class="line">        <span class="comment"># request.meta[&#x27;proxy&#x27;] = &#x27;http://103.130.172.34:8080&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 请求走</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line">      </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fake_useragent模块，可以随机生成user-aget  </span></span><br><span class="line"><span class="comment"># pip3 install fake-useragent</span></span><br><span class="line">	    <span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        <span class="built_in">print</span>(ua.ie)   <span class="comment">#随机打印ie浏览器任意版本</span></span><br><span class="line">        <span class="built_in">print</span>(ua.firefox) <span class="comment">#随机打印firefox浏览器任意版本</span></span><br><span class="line">        <span class="built_in">print</span>(ua.chrome)  <span class="comment">#随机打印chrome浏览器任意版本</span></span><br><span class="line">        <span class="built_in">print</span>(ua.random)  <span class="comment">#随机打印任意厂家的浏览器 </span></span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/crawler/" rel="tag"><i class="fa fa-tag"></i> crawler</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/72c362d8.html" rel="prev" title="Selenium的使用和xpath使用">
                  <i class="fa fa-chevron-left"></i> Selenium的使用和xpath使用
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/ff3e5230.html" rel="next" title="BeautifulSoup4的使用">
                  BeautifulSoup4的使用 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">klcc</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.4m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">21:10</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
